{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CourseWork.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "csme-uXTk4pG"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SeparableConv2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False):\n",
        "        super(SeparableConv2d, self).__init__()\n",
        "        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size, stride, padding, dilation, groups=in_channels, bias=bias)\n",
        "        self.pointwise = nn.Conv2d(in_channels, out_channels, 1, 1, 0, 1, 1, bias=bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.depthwise(x)\n",
        "        x = self.pointwise(x)\n",
        "        return x\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channeld, out_channels):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.residual_conv = nn.Conv2d(in_channels=in_channeld, out_channels=out_channels, kernel_size=1, stride=2, bias=False)\n",
        "        self.residual_bn = nn.BatchNorm2d(out_channels, momentum=0.99, eps=1e-3)\n",
        "        self.sepConv1 = SeparableConv2d(in_channels=in_channeld, out_channels=out_channels, kernel_size=3, bias=False, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels, momentum=0.99, eps=1e-3)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sepConv2 = SeparableConv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, bias=False, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels, momentum=0.99, eps=1e-3)\n",
        "        self.maxp = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        res = self.residual_conv(x)\n",
        "        res = self.residual_bn(res)\n",
        "        x = self.sepConv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.sepConv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.maxp(x)\n",
        "        return res + x\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Model, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, stride=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(8, affine=True, momentum=0.99, eps=1e-3)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=8, kernel_size=3, stride=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(8, momentum=0.99, eps=1e-3)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.module1 = ResidualBlock(in_channeld=8, out_channels=16)\n",
        "        self.module2 = ResidualBlock(in_channeld=16, out_channels=32)\n",
        "        self.module3 = ResidualBlock(in_channeld=32, out_channels=64)\n",
        "        self.module4 = ResidualBlock(in_channeld=64, out_channels=128)\n",
        "        self.last_conv = nn.Conv2d(in_channels=128, out_channels=num_classes, kernel_size=3, padding=1)\n",
        "        self.avgp = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = input\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.module1(x)\n",
        "        x = self.module2(x)\n",
        "        x = self.module3(x)\n",
        "        x = self.module4(x)\n",
        "        x = self.last_conv(x)\n",
        "        x = self.avgp(x)\n",
        "        x = x.view((x.shape[0], -1))\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVms55QsmqAm",
        "outputId": "ece5f2e2-6a23-4660-a34a-5465c8cfe576"
      },
      "source": [
        "!KAGGLE_USERNAME=dm33tri KAGGLE_KEY=efbaf0ad3856d5763312611da133d531 kaggle competitions download -c challenges-in-representation-learning-facial-expression-recognition-challenge"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "Downloading train.csv.zip to /content\n",
            " 79% 61.0M/77.3M [00:00<00:00, 107MB/s] \n",
            "100% 77.3M/77.3M [00:00<00:00, 131MB/s]\n",
            "Downloading icml_face_data.csv.zip to /content\n",
            " 87% 84.0M/96.6M [00:01<00:00, 72.0MB/s]\n",
            "100% 96.6M/96.6M [00:01<00:00, 83.1MB/s]\n",
            "Downloading example_submission.csv to /content\n",
            "  0% 0.00/7.01k [00:00<?, ?B/s]\n",
            "100% 7.01k/7.01k [00:00<00:00, 6.44MB/s]\n",
            "Downloading fer2013.tar.gz to /content\n",
            " 92% 85.0M/92.0M [00:00<00:00, 84.3MB/s]\n",
            "100% 92.0M/92.0M [00:01<00:00, 90.0MB/s]\n",
            "Downloading test.csv.zip to /content\n",
            " 78% 15.0M/19.3M [00:00<00:00, 57.6MB/s]\n",
            "100% 19.3M/19.3M [00:00<00:00, 75.6MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1fTM_U8npdG"
      },
      "source": [
        "!tar -xf /content/fer2013.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPf2DHBGoGnj",
        "outputId": "d8558050-497a-4910-b22f-f99745ad3c2f"
      },
      "source": [
        "!ls /content/fer2013"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fer2013.bib  fer2013.csv  README\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "x0pp40N-mGUa",
        "outputId": "b8b6e270-bc80-4050-8a1d-0aaa8fbabbf0"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import csv\n",
        "from PIL import Image\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "    from torchsummary import summary\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "shape = (44, 44)\n",
        "\n",
        "class DataSetFactory:\n",
        "    def __init__(self):\n",
        "        images = []\n",
        "        emotions = []\n",
        "        private_images = []\n",
        "        private_emotions = []\n",
        "        public_images = []\n",
        "        public_emotions = []\n",
        "        with open('/content/fer2013/fer2013.csv', 'r') as csvin:\n",
        "            data = csv.reader(csvin)\n",
        "            next(data)\n",
        "            for row in data:\n",
        "                face = [int(pixel) for pixel in row[1].split()]\n",
        "                face = np.asarray(face).reshape(48, 48)\n",
        "                face = face.astype('uint8')\n",
        "                if row[-1] == 'Training':\n",
        "                    emotions.append(int(row[0]))\n",
        "                    images.append(Image.fromarray(face))\n",
        "                elif row[-1] == \"PrivateTest\":\n",
        "                    private_emotions.append(int(row[0]))\n",
        "                    private_images.append(Image.fromarray(face))\n",
        "                elif row[-1] == \"PublicTest\":\n",
        "                    public_emotions.append(int(row[0]))\n",
        "                    public_images.append(Image.fromarray(face))\n",
        "        print('training size %d : private val size %d : public val size %d' % (\n",
        "            len(images), len(private_images), len(public_images)))\n",
        "        train_transform = transforms.Compose([\n",
        "            transforms.RandomCrop(shape[0]),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            ToTensor(),\n",
        "        ])\n",
        "        val_transform = transforms.Compose([\n",
        "            transforms.CenterCrop(shape[0]),\n",
        "            ToTensor(),\n",
        "        ])\n",
        "        self.training = DataSet(transform=train_transform, images=images, emotions=emotions)\n",
        "        self.private = DataSet(transform=val_transform, images=private_images, emotions=private_emotions)\n",
        "        self.public = DataSet(transform=val_transform, images=public_images, emotions=public_emotions)\n",
        "\n",
        "class DataSet(torch.utils.data.Dataset):\n",
        "    def __init__(self, transform=None, images=None, emotions=None):\n",
        "        self.transform = transform\n",
        "        self.images = images\n",
        "        self.emotions = emotions\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = self.images[index]\n",
        "        emotion = self.emotions[index]\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "        return image, emotion\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "batch_size = 128\n",
        "lr = 0.01\n",
        "epochs = 300\n",
        "learning_rate_decay_start = 80\n",
        "learning_rate_decay_every = 5\n",
        "learning_rate_decay_rate = 0.9\n",
        "classes = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
        "network = Model(num_classes=len(classes)).to(device)\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "    summary(network, (1, shape[0], shape[1]))\n",
        "\n",
        "optimizer = torch.optim.SGD(network.parameters(), lr=lr, momentum=0.9, weight_decay=5e-3)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "factory = DataSetFactory()\n",
        "training_loader = DataLoader(factory.training, batch_size=batch_size, shuffle=True, num_workers=1)\n",
        "\n",
        "validation_loader = {\n",
        "    'private': DataLoader(factory.private, batch_size=batch_size, shuffle=True, num_workers=1),\n",
        "    'public': DataLoader(factory.public, batch_size=batch_size, shuffle=True, num_workers=1)\n",
        "}\n",
        "\n",
        "min_validation_loss = {\n",
        "    'private': 10000,\n",
        "    'public': 10000,\n",
        "}\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    network.train()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    total_train_loss = 0\n",
        "    if epoch > learning_rate_decay_start and learning_rate_decay_start >= 0:\n",
        "        frac = (epoch - learning_rate_decay_start) // learning_rate_decay_every\n",
        "        decay_factor = learning_rate_decay_rate ** frac\n",
        "        current_lr = lr * decay_factor\n",
        "        for group in optimizer.param_groups:\n",
        "            group['lr'] = current_lr\n",
        "    else:\n",
        "        current_lr = lr\n",
        "    print('learning_rate: %s' % str(current_lr))\n",
        "    for i, (x_train, y_train) in enumerate(training_loader):\n",
        "        optimizer.zero_grad()\n",
        "        x_train = x_train.to(device)\n",
        "        y_train = y_train.to(device)\n",
        "        y_predicted = network(x_train)\n",
        "        loss = criterion(y_predicted, y_train)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        _, predicted = torch.max(y_predicted.data, 1)\n",
        "        total_train_loss += loss.data\n",
        "        total += y_train.size(0)\n",
        "        correct += predicted.eq(y_train.data).sum()\n",
        "    accuracy = 100. * float(correct) / total\n",
        "    print('Epoch [%d/%d] Training Loss: %.4f, Accuracy: %.4f' % (\n",
        "        epoch + 1, epochs, total_train_loss / (i + 1), accuracy))\n",
        "    network.eval()\n",
        "    with torch.no_grad():\n",
        "        for name in ['private', 'public']:\n",
        "            total = 0\n",
        "            correct = 0\n",
        "            total_validation_loss = 0\n",
        "            for j, (x_val, y_val) in enumerate(validation_loader[name]):\n",
        "                x_val = x_val.to(device)\n",
        "                y_val = y_val.to(device)\n",
        "                y_val_predicted = network(x_val)\n",
        "                val_loss = criterion(y_val_predicted, y_val)\n",
        "                _, predicted = torch.max(y_val_predicted.data, 1)\n",
        "                total_validation_loss += val_loss.data\n",
        "                total += y_val.size(0)\n",
        "                correct += predicted.eq(y_val.data).sum()\n",
        "            accuracy = 100. * float(correct) / total\n",
        "            if total_validation_loss <= min_validation_loss[name]:\n",
        "                min_validation_loss[name] = total_validation_loss\n",
        "            print('Epoch [%d/%d] %s validation Loss: %.4f, Accuracy: %.4f' % (\n",
        "                epoch + 1, epochs, name, total_validation_loss / (j + 1), accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 42, 42]              72\n",
            "       BatchNorm2d-2            [-1, 8, 42, 42]              16\n",
            "              ReLU-3            [-1, 8, 42, 42]               0\n",
            "            Conv2d-4            [-1, 8, 40, 40]             576\n",
            "       BatchNorm2d-5            [-1, 8, 40, 40]              16\n",
            "              ReLU-6            [-1, 8, 40, 40]               0\n",
            "            Conv2d-7           [-1, 16, 20, 20]             128\n",
            "       BatchNorm2d-8           [-1, 16, 20, 20]              32\n",
            "            Conv2d-9            [-1, 8, 40, 40]              72\n",
            "           Conv2d-10           [-1, 16, 40, 40]             128\n",
            "  SeparableConv2d-11           [-1, 16, 40, 40]               0\n",
            "      BatchNorm2d-12           [-1, 16, 40, 40]              32\n",
            "             ReLU-13           [-1, 16, 40, 40]               0\n",
            "           Conv2d-14           [-1, 16, 40, 40]             144\n",
            "           Conv2d-15           [-1, 16, 40, 40]             256\n",
            "  SeparableConv2d-16           [-1, 16, 40, 40]               0\n",
            "      BatchNorm2d-17           [-1, 16, 40, 40]              32\n",
            "        MaxPool2d-18           [-1, 16, 20, 20]               0\n",
            "    ResidualBlock-19           [-1, 16, 20, 20]               0\n",
            "           Conv2d-20           [-1, 32, 10, 10]             512\n",
            "      BatchNorm2d-21           [-1, 32, 10, 10]              64\n",
            "           Conv2d-22           [-1, 16, 20, 20]             144\n",
            "           Conv2d-23           [-1, 32, 20, 20]             512\n",
            "  SeparableConv2d-24           [-1, 32, 20, 20]               0\n",
            "      BatchNorm2d-25           [-1, 32, 20, 20]              64\n",
            "             ReLU-26           [-1, 32, 20, 20]               0\n",
            "           Conv2d-27           [-1, 32, 20, 20]             288\n",
            "           Conv2d-28           [-1, 32, 20, 20]           1,024\n",
            "  SeparableConv2d-29           [-1, 32, 20, 20]               0\n",
            "      BatchNorm2d-30           [-1, 32, 20, 20]              64\n",
            "        MaxPool2d-31           [-1, 32, 10, 10]               0\n",
            "    ResidualBlock-32           [-1, 32, 10, 10]               0\n",
            "           Conv2d-33             [-1, 64, 5, 5]           2,048\n",
            "      BatchNorm2d-34             [-1, 64, 5, 5]             128\n",
            "           Conv2d-35           [-1, 32, 10, 10]             288\n",
            "           Conv2d-36           [-1, 64, 10, 10]           2,048\n",
            "  SeparableConv2d-37           [-1, 64, 10, 10]               0\n",
            "      BatchNorm2d-38           [-1, 64, 10, 10]             128\n",
            "             ReLU-39           [-1, 64, 10, 10]               0\n",
            "           Conv2d-40           [-1, 64, 10, 10]             576\n",
            "           Conv2d-41           [-1, 64, 10, 10]           4,096\n",
            "  SeparableConv2d-42           [-1, 64, 10, 10]               0\n",
            "      BatchNorm2d-43           [-1, 64, 10, 10]             128\n",
            "        MaxPool2d-44             [-1, 64, 5, 5]               0\n",
            "    ResidualBlock-45             [-1, 64, 5, 5]               0\n",
            "           Conv2d-46            [-1, 128, 3, 3]           8,192\n",
            "      BatchNorm2d-47            [-1, 128, 3, 3]             256\n",
            "           Conv2d-48             [-1, 64, 5, 5]             576\n",
            "           Conv2d-49            [-1, 128, 5, 5]           8,192\n",
            "  SeparableConv2d-50            [-1, 128, 5, 5]               0\n",
            "      BatchNorm2d-51            [-1, 128, 5, 5]             256\n",
            "             ReLU-52            [-1, 128, 5, 5]               0\n",
            "           Conv2d-53            [-1, 128, 5, 5]           1,152\n",
            "           Conv2d-54            [-1, 128, 5, 5]          16,384\n",
            "  SeparableConv2d-55            [-1, 128, 5, 5]               0\n",
            "      BatchNorm2d-56            [-1, 128, 5, 5]             256\n",
            "        MaxPool2d-57            [-1, 128, 3, 3]               0\n",
            "    ResidualBlock-58            [-1, 128, 3, 3]               0\n",
            "           Conv2d-59              [-1, 7, 3, 3]           8,071\n",
            "AdaptiveAvgPool2d-60              [-1, 7, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 56,951\n",
            "Trainable params: 56,951\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 4.11\n",
            "Params size (MB): 0.22\n",
            "Estimated Total Size (MB): 4.33\n",
            "----------------------------------------------------------------\n",
            "training size 28709 : private val size 3589 : public val size 3589\n",
            "learning_rate: 0.01\n",
            "Epoch [1/300] Training Loss: 1.7366, Accuracy: 31.1226\n",
            "Epoch [1/300] private validation Loss: 1.6928, Accuracy: 35.2744\n",
            "Epoch [1/300] public validation Loss: 1.6731, Accuracy: 35.4974\n",
            "learning_rate: 0.01\n",
            "Epoch [2/300] Training Loss: 1.4930, Accuracy: 42.7148\n",
            "Epoch [2/300] private validation Loss: 1.4190, Accuracy: 45.4444\n",
            "Epoch [2/300] public validation Loss: 1.3943, Accuracy: 46.4196\n",
            "learning_rate: 0.01\n",
            "Epoch [3/300] Training Loss: 1.3681, Accuracy: 47.7237\n",
            "Epoch [3/300] private validation Loss: 1.3009, Accuracy: 50.5433\n",
            "Epoch [3/300] public validation Loss: 1.3174, Accuracy: 49.3731\n",
            "learning_rate: 0.01\n",
            "Epoch [4/300] Training Loss: 1.2996, Accuracy: 50.6287\n",
            "Epoch [4/300] private validation Loss: 1.4696, Accuracy: 46.5589\n",
            "Epoch [4/300] public validation Loss: 1.5082, Accuracy: 45.7509\n",
            "learning_rate: 0.01\n",
            "Epoch [5/300] Training Loss: 1.2515, Accuracy: 52.4609\n",
            "Epoch [5/300] private validation Loss: 1.2139, Accuracy: 53.2460\n",
            "Epoch [5/300] public validation Loss: 1.2461, Accuracy: 52.3266\n",
            "learning_rate: 0.01\n",
            "Epoch [6/300] Training Loss: 1.2082, Accuracy: 54.1259\n",
            "Epoch [6/300] private validation Loss: 1.2145, Accuracy: 54.2770\n",
            "Epoch [6/300] public validation Loss: 1.2607, Accuracy: 52.9117\n",
            "learning_rate: 0.01\n",
            "Epoch [7/300] Training Loss: 1.1888, Accuracy: 55.1569\n",
            "Epoch [7/300] private validation Loss: 1.1998, Accuracy: 55.2243\n",
            "Epoch [7/300] public validation Loss: 1.2108, Accuracy: 53.9983\n",
            "learning_rate: 0.01\n",
            "Epoch [8/300] Training Loss: 1.1723, Accuracy: 55.4321\n",
            "Epoch [8/300] private validation Loss: 1.1689, Accuracy: 56.1716\n",
            "Epoch [8/300] public validation Loss: 1.1974, Accuracy: 54.5556\n",
            "learning_rate: 0.01\n",
            "Epoch [9/300] Training Loss: 1.1519, Accuracy: 55.9790\n",
            "Epoch [9/300] private validation Loss: 1.1501, Accuracy: 56.7568\n",
            "Epoch [9/300] public validation Loss: 1.1716, Accuracy: 55.3636\n",
            "learning_rate: 0.01\n",
            "Epoch [10/300] Training Loss: 1.1426, Accuracy: 56.7766\n",
            "Epoch [10/300] private validation Loss: 1.1545, Accuracy: 55.9766\n",
            "Epoch [10/300] public validation Loss: 1.1870, Accuracy: 54.4720\n",
            "learning_rate: 0.01\n",
            "Epoch [11/300] Training Loss: 1.1286, Accuracy: 57.3618\n",
            "saving new model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-7497eb53eb40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    146\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'saving new model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'net'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m                     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'../trained/%s_model_%d_%d.t7'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m                 \u001b[0mmin_validation_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_validation_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             print('Epoch [%d/%d] %s validation Loss: %.4f, Accuracy: %.4f' % (\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0m_check_dill_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../trained/private_model_11_56.t7'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILFhx9XGyfB_",
        "outputId": "65e1b190-c709-442b-f294-b05d0bbf3bef"
      },
      "source": [
        "network.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "  (bn1): BatchNorm2d(8, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
              "  (relu1): ReLU()\n",
              "  (conv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "  (bn2): BatchNorm2d(8, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
              "  (relu2): ReLU()\n",
              "  (module1): ResidualBlock(\n",
              "    (residual_conv): Conv2d(8, 16, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "    (residual_bn): BatchNorm2d(16, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
              "    (sepConv1): SeparableConv2d(\n",
              "      (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
              "      (pointwise): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    )\n",
              "    (bn1): BatchNorm2d(16, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "    (sepConv2): SeparableConv2d(\n",
              "      (depthwise): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
              "      (pointwise): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    )\n",
              "    (bn2): BatchNorm2d(16, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
              "    (maxp): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (module2): ResidualBlock(\n",
              "    (residual_conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "    (residual_bn): BatchNorm2d(32, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
              "    (sepConv1): SeparableConv2d(\n",
              "      (depthwise): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
              "      (pointwise): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    )\n",
              "    (bn1): BatchNorm2d(32, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "    (sepConv2): SeparableConv2d(\n",
              "      (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "      (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    )\n",
              "    (bn2): BatchNorm2d(32, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
              "    (maxp): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (module3): ResidualBlock(\n",
              "    (residual_conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "    (residual_bn): BatchNorm2d(64, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
              "    (sepConv1): SeparableConv2d(\n",
              "      (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "      (pointwise): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    )\n",
              "    (bn1): BatchNorm2d(64, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "    (sepConv2): SeparableConv2d(\n",
              "      (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "      (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    )\n",
              "    (bn2): BatchNorm2d(64, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
              "    (maxp): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (module4): ResidualBlock(\n",
              "    (residual_conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "    (residual_bn): BatchNorm2d(128, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
              "    (sepConv1): SeparableConv2d(\n",
              "      (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "      (pointwise): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    )\n",
              "    (bn1): BatchNorm2d(128, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "    (sepConv2): SeparableConv2d(\n",
              "      (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
              "      (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    )\n",
              "    (bn2): BatchNorm2d(128, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
              "    (maxp): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (last_conv): Conv2d(128, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (avgp): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nM0BoJ2mxRKv"
      },
      "source": [
        "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
        "\n",
        "traced = torch.jit.trace(network, torch.rand(1, 1, 44, 44))\n",
        "optimize_for_mobile(traced)\n",
        "traced.save(\"model.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}